{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49c91211-5e58-4a1f-a70e-7f4d5d24cd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78adb21e-eccd-4cd0-be75-c2d622ce3a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_ai_api_key import api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3863f0a4-5b15-4c49-885b-bfe39ccd3303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086eb693-0548-4cc9-8362-1cce9f7fbec6",
   "metadata": {},
   "source": [
    "# Simple chatbot using Openai and langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e08b20b1-ff28-4591-9e77-5008ea4c6d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm just a computer program, so I don't have feelings, but I'm here to help you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    api_key = api_key\n",
    ")\n",
    "\n",
    "response = llm.invoke('Hello, How are you?')\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8bcb84-f50d-43bb-be6a-b45c58702703",
   "metadata": {},
   "source": [
    "### Save api key in environment file"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7f31e95d-2fee-49b9-a2e4-d5d15106cb86",
   "metadata": {},
   "source": [
    "load environment variables from a .env file into your Python application's environment. This is particularly useful for managing sensitive information like API keys, database credentials, and other configuration settings securely and conveniently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "358e7010-7a91-4e0c-b0ca-3026421a7100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# pip install python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "# OPENAI_API_KEY = 'your api key' in .env file\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "response = llm.invoke('Hello, How are you?')\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d035d307-4092-416b-9b0a-90d56659cd2a",
   "metadata": {},
   "source": [
    "### Set type of model, temperature and max-token for the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29f45725-a8bd-41f0-82b0-2c7a9ef9b6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='Machine learning is a subset of artificial intelligence that involves the development of algorithms and statistical models that enable computers to learn from and make predictions or decisions based on data without being explicitly programmed. Machine learning algorithms use patterns and inference to make decisions and improve their performance over time as they are exposed to more data.', response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 12, 'total_tokens': 72}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-9cfe68df-d457-4dd2-b0ce-3e7f6f32807f-0', usage_metadata={'input_tokens': 12, 'output_tokens': 60, 'total_tokens': 72}), AIMessage(content='Few-shot learning is a machine learning technique that aims to train models with only a small amount of labeled data. This is in contrast to traditional machine learning approaches that require large amounts of labeled data to achieve good performance. Few-shot learning is particularly useful in scenarios where collecting large amounts of labeled data is difficult or expensive. It typically involves training a model on a small number of examples from each class and then using that model to make predictions on new, unseen data.', response_metadata={'token_usage': {'completion_tokens': 92, 'prompt_tokens': 12, 'total_tokens': 104}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-6078c816-fd53-42a3-98e2-a26c71aea145-0', usage_metadata={'input_tokens': 12, 'output_tokens': 92, 'total_tokens': 104})]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatOpenAI(\n",
    "    model = 'gpt-3.5-turbo', \n",
    "    temperature = 0, # 0:Factual response good for math, 1: for Creative answers good for poem, fiction writing\n",
    "    max_tokens = 1000,\n",
    "    verbose = True, # Debug the output from the model good for mode complex chains\n",
    ")\n",
    "\n",
    "response = llm.batch(['What is machine learning?', 'what is few-shot learning'])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "03f22a4a-0677-41cc-a618-bd0b125d6bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='1. Reinforcement learning\\n2. Unsupervised learning\\n3. Transfer learning\\n4. Semi-supervised learning\\n5. Self-supervised learning\\n6. Generative adversarial networks (GANs)\\n7. Deep learning\\n8. Natural language processing (NLP)\\n9. Computer vision\\n10. Bayesian learning' response_metadata={'token_usage': {'completion_tokens': 66, 'prompt_tokens': 41, 'total_tokens': 107}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-3474c183-201b-4a2c-a82a-677d98970de5-0' usage_metadata={'input_tokens': 41, 'output_tokens': 66, 'total_tokens': 107}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatOpenAI(\n",
    "    model = 'gpt-3.5-turbo', \n",
    "    temperature = 0, # 0:Factual response good for math, 1: for Creative answers good for poem, fiction writing\n",
    "    max_tokens = 1000,\n",
    "    verbose = True, # Debug the output from the model good for mode complex chains\n",
    ")\n",
    "\n",
    "response = llm.invoke('Give me a list of different learnings in AI. No need to explaain, just list the names like federated learning, few-shot learning, supervised learning.')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd6bc62-0862-4d11-82de-e29a31d99272",
   "metadata": {},
   "source": [
    "### Generating output in stream mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9d06fd43-8a97-4fcf-a3a2-14553c9783aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence (AI) is a rapidly evolving field that encompasses a wide range of technologies and applications. Here are some of the key learnings we have gained in AI:\n",
      "\n",
      "1. Machine Learning: Machine learning is a subset of AI that focuses on developing algorithms and models that can learn from data and make predictions or decisions without being explicitly programmed. Key learnings in machine learning include the importance of data quality, feature engineering, model selection, and hyperparameter tuning.\n",
      "\n",
      "2. Deep Learning: Deep learning is a subset of machine learning that uses neural networks with multiple layers to learn complex patterns in data. Key learnings in deep learning include the importance of network architecture design, training strategies, regularization techniques, and interpretability of models.\n",
      "\n",
      "3. Natural Language Processing (NLP): NLP is a branch of AI that focuses on enabling computers to understand, interpret, and generate human language. Key learnings in NLP include the development of language models, sentiment analysis, named entity recognition, and machine translation.\n",
      "\n",
      "4. Computer Vision: Computer vision is a field of AI that focuses on enabling computers to interpret and understand visual information from the world. Key learnings in computer vision include object detection, image classification, image segmentation, and video analysis.\n",
      "\n",
      "5. Reinforcement Learning: Reinforcement learning is a type of machine learning that focuses on training agents to make sequential decisions in an environment to maximize a reward. Key learnings in reinforcement learning include the exploration-exploitation trade-off, reward shaping, policy optimization, and model-based reinforcement learning.\n",
      "\n",
      "6. Ethical and Responsible AI: As AI technologies become more pervasive in society, there is a growing emphasis on the ethical and responsible use of AI. Key learnings in this area include bias and fairness in AI systems, transparency and interpretability of models, accountability and governance of AI systems, and privacy and security considerations.\n",
      "\n",
      "Overall, the field of AI continues to evolve rapidly, and there are many exciting opportunities for further learning and innovation in the future."
     ]
    }
   ],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatOpenAI(\n",
    "    model = 'gpt-3.5-turbo', \n",
    "    temperature = 0, # 0:Factual response good for math, 1: for Creative answers good for poem, fiction writing\n",
    "    max_tokens = 1000,\n",
    "    verbose = True, # Debug the output from the model good for mode complex chains\n",
    ")\n",
    "\n",
    "response = llm.stream('Introduce different learnings we have in AI 300 words')\n",
    "for res in response:\n",
    "    print(res.content, end = '', flush = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f58cf1-8c91-43e9-adb5-a06be8863391",
   "metadata": {},
   "source": [
    "## Using Prompt templates to tell the model how to respond (Control conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efc9a0e8-104e-4fdc-8a44-bea0ac81f955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Deep learning is a subset of machine learning that aims to model high-level abstractions in data by using multiple layers of neural networks. It is a type of artificial intelligence that is inspired by the way the human brain works. Deep learning algorithms are designed to automatically learn and improve from experience without being explicitly programmed.\\n\\nOne of the key features of deep learning is its ability to automatically discover intricate patterns and relationships in data, which can be used to make predictions, classify images, understand speech, and more. This is achieved through the use of artificial neural networks, which are composed of interconnected nodes that process and analyze data in a hierarchical manner.\\n\\nDeep learning has been successfully applied to a wide range of applications, including computer vision, natural language processing, speech recognition, and healthcare. For example, deep learning algorithms have been used to develop self-driving cars, improve medical imaging techniques, and enhance language translation services.\\n\\nOne of the most popular deep learning architectures is the convolutional neural network (CNN), which is particularly effective for image recognition tasks. Another widely used architecture is the recurrent neural network (RNN), which is well-suited for processing sequential data such as speech or text.\\n\\nDespite its many successes, deep learning is not without its challenges. Training deep neural networks can be computationally intensive and requires large amounts of labeled data. Additionally, deep learning models can be prone to overfitting, where they perform well on training data but poorly on new, unseen data.\\n\\nOverall, deep learning has revolutionized the field of artificial intelligence and has the potential to drive further advancements in technology and society. As researchers continue to improve algorithms and develop new architectures, the capabilities of deep learning are expected to grow even further in the coming years.' response_metadata={'token_usage': {'completion_tokens': 343, 'prompt_tokens': 16, 'total_tokens': 359}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-892ef7a0-313f-4857-84a2-8c5b06537f78-0' usage_metadata={'input_tokens': 16, 'output_tokens': 343, 'total_tokens': 359}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatOpenAI(\n",
    "    model = 'gpt-3.5-turbo'\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template('Tell me about {input} in 300 words')\n",
    "\n",
    "# Create llm chain\n",
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke({'input': 'deep learning'})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "052f87a1-6b78-4af8-b9da-3220ee71dfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='1. What is deep learning?\\na) A type of machine learning that uses neural networks with multiple layers\\nb) A type of reinforcement learning algorithm\\nc) A method for supervised learning only\\nd) A technique for feature selection\\n\\n2. Which of the following is a common activation function used in deep learning?\\na) Sigmoid\\nb) Linear\\nc) Mean Squared Error\\nd) K-Means\\n\\n3. What is the purpose of using convolutional neural networks (CNNs) in deep learning?\\na) They are used for natural language processing tasks\\nb) They are specialized for image recognition tasks\\nc) They are used for anomaly detection in time series data\\nd) They are specifically designed for clustering problems' response_metadata={'token_usage': {'completion_tokens': 150, 'prompt_tokens': 34, 'total_tokens': 184}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-947c2c21-9adc-46f1-ad63-cc2e00896949-0' usage_metadata={'input_tokens': 34, 'output_tokens': 150, 'total_tokens': 184}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatOpenAI(\n",
    "    model = 'gpt-3.5-turbo'\n",
    ")\n",
    "\n",
    "# we can say the model what is its role, what type of response we want, ...\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "    (\"system\", \"You are a professor in machine learning and we want to design 3 multiple choice questions for a test.\"),\n",
    "    ('human', '{input}')\n",
    "    ])\n",
    "\n",
    "# Create llm chain\n",
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke({'input': 'deep learning'})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139a230b-e693-428d-9d34-3be6b71a0843",
   "metadata": {},
   "source": [
    "##### Get a list of desired outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "685dec9f-66f8-46a1-94c8-2074a25561af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='falling snow, deep snow, powdery snow, fresh snow, heavy snow, snow-covered mountains, snow-capped peaks, snowflakes, snowstorm, snowdrifts' response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 30, 'total_tokens': 68}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-4fd01ed3-c23a-45bb-895f-a13b481391b4-0' usage_metadata={'input_tokens': 30, 'output_tokens': 38, 'total_tokens': 68}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatOpenAI(\n",
    "    model = 'gpt-3.5-turbo'\n",
    ")\n",
    "\n",
    "# we can say the model what is its role, what type of response we want, ...\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "    (\"system\", \"Generate 10 collocations for the input word. Return the results as a comma separated list\"),\n",
    "    ('human', '{input}')\n",
    "    ])\n",
    "\n",
    "# Create llm chain\n",
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke({'input': 'snow'})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3b98bc9-e285-464b-9eb2-5b9320ea8812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "print(type(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac179a0f-aa71-442a-8301-48964f92c3b4",
   "metadata": {},
   "source": [
    "# Parsing outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c286677-c437-4688-84a5-502d40464a67",
   "metadata": {},
   "source": [
    "#### Get the output as String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1f174a62-0668-4763-abac-b5a90ba9c3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "falling snow, deep snow, fresh snow, heavy snow, snow-covered mountains, snow-capped peaks, thick snow, powdery snow, snowflake, snowstorm\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatOpenAI(\n",
    "    model = 'gpt-3.5-turbo'\n",
    ")\n",
    "\n",
    "\n",
    "def resultToStr():\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "        (\"system\", \"Generate 10 collocations for the input word. Return the results as a comma separated list\"),\n",
    "        ('human', '{input}')\n",
    "        ])\n",
    "\n",
    "    parser = StrOutputParser()\n",
    "    # Create llm chain\n",
    "    chain = prompt | llm | parser\n",
    "    \n",
    "    response = chain.invoke({'input': 'snow'})\n",
    "    return response\n",
    "\n",
    "print(resultToStr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4508f9b8-903c-4ee1-8b12-9db119d813f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(resultToStr()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5d7d88-3a1c-4712-b7f5-190c87d11743",
   "metadata": {},
   "source": [
    "#### Get the output as List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b475bbed-2ebf-48b3-8f81-44d5b4459f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['falling snow', 'deep snow', 'fresh snow', 'heavy snow', 'powdery snow', 'snow covered', 'snow capped', 'snow drifts', 'snow flurries', 'melting snow']\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatOpenAI(\n",
    "    model = 'gpt-3.5-turbo'\n",
    ")\n",
    "\n",
    "\n",
    "def resultToList():\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "        (\"system\", \"Generate 10 collocations for the input word. Return the results as a comma separated list\"),\n",
    "        ('human', '{input}')\n",
    "        ])\n",
    "\n",
    "    parser = CommaSeparatedListOutputParser()\n",
    "    # Create llm chain\n",
    "    chain = prompt | llm | parser\n",
    "    \n",
    "    response = chain.invoke({'input': 'snow'})\n",
    "    return response\n",
    "\n",
    "print(resultToList())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccfbfa1-935a-4a59-84c5-72b420e8f757",
   "metadata": {},
   "source": [
    "#### Get the output as Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c17e6fca-15c7-413e-92d5-5ffbc147c514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'Ford Mustang', 'year': 2017, 'reach_100': 4}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatOpenAI(\n",
    "    model = 'gpt-3.5-turbo'\n",
    ")\n",
    "\n",
    "\n",
    "def resultToJson():\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "        (\"system\", \"Extract the information from the sentence based on the following format.\\n Formating instruction: {format_instruction}\"),\n",
    "        ('human', '{input}')\n",
    "        ])\n",
    "\n",
    "    class Auto(BaseModel):\n",
    "        model: str = Field(description = 'What is the model of the car?')\n",
    "        year: int = Field(description = 'What is the year of the car?')\n",
    "        reach_100: int = Field(description= \"How long does it take to reach 100KM?\")\n",
    "    \n",
    "    parser = JsonOutputParser(pydantic_object = Auto)\n",
    "    \n",
    "    # Create llm chain\n",
    "    chain = prompt | llm | parser\n",
    "    \n",
    "    response = chain.invoke({\n",
    "        'input': 'This 2017 Ford Mustang car is amazing with having V8 for the engine, and reaching to 100KM under 4 seconds', \n",
    "        \"format_instruction\": parser.get_format_instructions() # Generate instruction that model understands\n",
    "    })\n",
    "    return response\n",
    "\n",
    "print(resultToJson())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4980a205-dd1f-4508-8857-eeb90f189719",
   "metadata": {},
   "source": [
    "### Connecting LLM to Specific source using LangChain"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6de7a03c-c030-4707-8168-05bd7e0e539f",
   "metadata": {},
   "source": [
    "https://python.langchain.com/v0.1/docs/modules/data_connection/document_loaders/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5946ce1f-e380-489b-bf8d-717af64c63ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://python.langchain.com/v0.1/docs/modules/data_connection/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6889d03c-9f82-422e-841c-290003c37270",
   "metadata": {},
   "source": [
    "Csv, Pdf, Documents, Website, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2208df1-da76-4170-ab99-d66aed973fd0",
   "metadata": {},
   "source": [
    "##### Asking a question from the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b482edd0-a5e8-4a21-afa5-97a7950a36a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The minimum CRS score for the last draw on May 31 was 380.' response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 32, 'total_tokens': 48}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-e513b377-97bd-442c-94df-5e5876bc204c-0' usage_metadata={'input_tokens': 32, 'output_tokens': 16, 'total_tokens': 48}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "llm_model = ChatOpenAI(\n",
    "    model = 'gpt-3.5-turbo'\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template('''\n",
    "        Answer the questions: Question: {input}\n",
    "        ''')  \n",
    "# Create llm chain\n",
    "chain = prompt | llm \n",
    "    \n",
    "response = chain.invoke({'input': 'What is the  minimum CRS score for the last draw on May 31?'})\n",
    "print(response)\n",
    "#https://www.cicnews.com/2024/07/express-entry-1390-candidates-invited-in-latest-pnp-only-draw-0745309.html#gs.bs9dnf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19500bd6-74d9-47fc-84eb-c92d5f6aa2e3",
   "metadata": {},
   "source": [
    "#### Give the model specific information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "11d6881c-3887-4a3f-8dde-ff31e2ef8269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The minimum CRS score for the last draw on May 31 was 522.' response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 153, 'total_tokens': 169}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-4d746cdb-4afc-4c30-aa74-36ffd69fe2bb-0' usage_metadata={'input_tokens': 153, 'output_tokens': 16, 'total_tokens': 169}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "llm_model = ChatOpenAI(\n",
    "    model = 'gpt-3.5-turbo'\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template('''\n",
    "        Answer the questions: \n",
    "        Context: Today's minimum CRS score represent's the lowest score of the year in a non-category based selection draw and is also lower than the last CEC-only draw on May 31 (522). So far this month IRCC has issued  17,361 ITAs over six seperate draws. Yesterday, IRCC invited 1,391 candidates in a Provincial Nominee Program (PNP)-only draw with a minimum CRS of 670. Before that, IRCC most recently invited 3,200 candidates in a category-based selected draw  for French proficiency on July 8.\n",
    "        Question: {input}\n",
    "        ''')  \n",
    "# Create llm chain\n",
    "chain = prompt | llm \n",
    "    \n",
    "response = chain.invoke({'input': 'What is the  minimum CRS score for the last draw on May 31?'})\n",
    "print(response)\n",
    "#https://www.cicnews.com/2024/07/express-entry-1390-candidates-invited-in-latest-pnp-only-draw-0745309.html#gs.bs9dnf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfd0046-409e-4514-a6ee-e2e21d7a2cc9",
   "metadata": {},
   "source": [
    "#### Put the information in the document variable (document or documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "50e770a2-1a36-413a-8731-a57267865263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Answer: The minimum CRS score for the last draw on May 31 was 522.' response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 164, 'total_tokens': 182}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-7bae5c31-dab2-4390-8cf8-3e71648fee19-0' usage_metadata={'input_tokens': 164, 'output_tokens': 18, 'total_tokens': 182}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "doc1 = Document(\n",
    "    page_content = '''\n",
    "    Today's minimum CRS score represent's the lowest score of the year in a non-category based selection draw and is also lower than the last CEC-only draw on May 31 (522). So far this month IRCC has issued  17,361 ITAs over six seperate draws. Yesterday, IRCC invited 1,391 candidates in a Provincial Nominee Program (PNP)-only draw with a minimum CRS of 670. Before that, IRCC most recently invited 3,200 candidates in a category-based selected draw  for French proficiency on July 8.\n",
    "    '''\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "llm_model = ChatOpenAI(\n",
    "    model = 'gpt-3.5-turbo'\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template('''\n",
    "        Answer the questions: \n",
    "        Context: {context}\n",
    "        Question: {input}\n",
    "        ''')  \n",
    "# Create llm chain\n",
    "chain = prompt | llm \n",
    "    \n",
    "response = chain.invoke({\n",
    "    'input': 'What is the  minimum CRS score for the last draw on May 31?',\n",
    "    'context': [doc1]\n",
    "})\n",
    "print(response)\n",
    "#https://www.cicnews.com/2024/07/express-entry-1390-candidates-invited-in-latest-pnp-only-draw-0745309.html#gs.bs9dnf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9be3f0-8abf-4159-8daf-a986f1eb3971",
   "metadata": {},
   "source": [
    "#### Add class create_stuff_documents_chain for retrieval later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "23aa0392-663e-4318-9acd-fbee2aaac514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum CRS score for the last draw on May 31 was 522.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.documents import Document\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "doc1 = Document(\n",
    "    page_content = '''\n",
    "    Today's minimum CRS score represent's the lowest score of the year in a non-category based selection draw and is also lower than the last CEC-only draw on May 31 (522). So far this month IRCC has issued  17,361 ITAs over six seperate draws. Yesterday, IRCC invited 1,391 candidates in a Provincial Nominee Program (PNP)-only draw with a minimum CRS of 670. Before that, IRCC most recently invited 3,200 candidates in a category-based selected draw  for French proficiency on July 8.\n",
    "    '''\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "llm_model = ChatOpenAI(\n",
    "    model = 'gpt-3.5-turbo'\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template('''\n",
    "        Answer the questions: \n",
    "        Context: {context}\n",
    "        Question: {input}\n",
    "        ''')  \n",
    "# Create llm chain\n",
    "#chain = prompt | llm \n",
    "chain = create_stuff_documents_chain(\n",
    "    llm = llm_model, \n",
    "    prompt = prompt\n",
    ")\n",
    "\n",
    "    \n",
    "response = chain.invoke({\n",
    "    'input': 'What is the  minimum CRS score for the last draw on May 31?',\n",
    "    'context': [doc1]\n",
    "})\n",
    "print(response)\n",
    "#https://www.cicnews.com/2024/07/express-entry-1390-candidates-invited-in-latest-pnp-only-draw-0745309.html#gs.bs9dnf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b7729b-5a97-4d5c-b379-08019218627c",
   "metadata": {},
   "source": [
    "#### Write a function to crawl the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "30c4f690-c3a1-4b25-b209-c750eb8c05c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'https://www.cicnews.com/2024/07/express-entry-1390-candidates-invited-in-latest-pnp-only-draw-0745309.html#gs.bs9dnf', 'title': 'IRCC invites 6,300 Canadian Experience Class candidates in latest Express Entry draw | CIC News', 'language': 'en-US'}, page_content=\"\\n\\n\\n\\n\\n\\nIRCC invites 6,300 Canadian Experience Class candidates in latest Express Entry draw | CIC News\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAbout us\\n\\n\\n\\n\\nMeet our partners\\n\\n\\n\\n\\nAdvertise with us \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMenu\\n\\n\\nClose\\n\\n\\n\\n\\n\\n\\nSubscribe\\n\\n\\n\\n\\n\\n\\n\\n\\nHome\\nExpress Entry\\nCanada\\nProvinces\\nFamily Sponsorship\\nStudy\\nWork\\nVisit\\nCitizenship\\nLife in Canada\\n \\n\\n\\n\\n\\n\\n\\n\\nIRCC invites 6,300 Canadian Experience Class candidates in latest Express Entry draw\\n\\n\\n\\n \\nEdana Robitaille\\n\\n\\nUpdated: Jul, 16, 2024 Published: July 16, 2024 \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nShare this article\\n\\n\\nCopy link\\r\\n\\t\\t\\t\\t\\t\\t\\t\\n\\nFacebook\\r\\n\\t\\t\\t\\t\\t\\t\\t\\n\\nE-mail\\r\\n\\t\\t\\t\\t\\t\\t\\t\\n\\nMessenger\\r\\n\\t\\t\\t\\t\\t\\t\\t\\n\\nReddit\\r\\n\\t\\t\\t\\t\\t\\t\\t\\n\\nTwitter\\r\\n\\t\\t\\t\\t\\t\\t\\t\\n\\nLinkedin\\r\\n\\t\\t\\t\\t\\t\\t\\t\\n\\nWhatsApp\\r\\n\\t\\t\\t\\t\\t\\t\\t\\n\\nTelegram\\r\\n\\t\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n119shares\\n\\n\\n \\n\\n\\n\\n\\nImmigration, Refugees, and Citizenship Canada (IRCC) has issued invitations to apply (ITAs) in the latest Express Entry draw\\nThe department issued 6,300 ITAs in a draw for Canadian Experience Class (CEC) candidates.\\nCandidates required a minimum Comprehensive Ranking System (CRS) score of 515 to be considered.\\nGet a Free Express Entry Assessment\\nToday's minimum CRS score represent's the lowest score of the year in a non-category based selection draw and is also lower than the last CEC-only draw on May 31 (522).\\nSo far this month IRCC has issued\\xa0 17,361 ITAs over six seperate draws.\\nYesterday, IRCC invited 1,391 candidates in a Provincial Nominee Program (PNP)-only draw with a minimum CRS of 670. Before that, IRCC most recently invited 3,200 candidates in a category-based selected draw\\xa0 for French proficiency on July 8.\\nCRS scores for PNP-only Express Entry draws tend to be higher than average because Express Entry candidates who have been successfully nominated for the PNP automatically receive an additional 600 CRS points on top of their existing score. For example, an Express Entry candidate with a score of 300 that is successfully nominated will then have an overall CRS of 900.\\nSummary of Express Entry draw results in 2024\\n\\n\\n\\n\\nDateDraw TypeNumber of ITAsMinimum CRS\\n\\n\\n\\n\\nJuly 17Canadian Experience Class6,300515\\n\\n\\nJuly 16Provincial Nominee Program1,391670\\n\\n\\nJuly 8French proficiency3,200420\\n\\n\\nJuly 5Healthcare occupations3,750445\\n\\n\\nJuly 4Trade occupations1,800436\\n\\n\\nJuly 2Provincial Nominee Program920739\\n\\n\\nJune 19Provincial Nominee Program1,499663\\n\\n\\nMay 31Canadian Experience Class3,000522\\n\\n\\nMay 30Provincial Nominee Program2,985676\\n\\n\\nApril 24French proficiency1,400410\\n\\n\\nApril 23General2,095529\\n\\n\\nApril 11STEM occupations4,500491\\n\\n\\nApril 10General1,280549\\n\\n\\nMarch 26French language proficiency1,500388\\n\\n\\nMarch 25General1,980524\\n\\n\\nMarch 13Transport occupations975430\\n\\n\\nMarch 12General2,850525\\n\\n\\nFebruary 29French language proficiency2,500336\\n\\n\\nFebruary 28General1,470534\\n\\n\\nFebruary 16Agriculture and agri-food occupations150437\\n\\n\\nFebruary 14Healthcare occupations3,500422\\n\\n\\nFebruary 13General1,490535\\n\\n\\nFebruary 1French language proficiency7,000365\\n\\n\\nJanuary 31General730541\\n\\n\\nJanuary 23General1,040543\\n\\n\\nJanuary 10General1,510546\\n\\n\\n\\n\\nWhat is Express Entry?\\nExpress Entry is an application management system for three economic immigration programs in Canada: the Federal Skilled Worker Program (FSWP), the Canadian Experience Class (CEC) and the Federal Skilled Trades Program (FSTP). Each program is a pathway to permanent residency in Canada.\\nThese programs use the Comprehensive Ranking System (CRS) to evaluate immigration candidates based on human capital factors such as occupation, age, education, language ability and work experience. Each factor receives a score, and the total creates a candidate’s CRS score.\\nThe system was introduced in 2015 as a means for IRCC to speed up processing time for successful applicants. The department has a published service standard of six months for these applications.\\nWhat is category-based selection?\\nCategory-based selection was launched in 2023 as a way for IRCC to further target the Express Entry candidates who are the most likely to help Canada fill urgent gaps in it’s workforce, or strengthen a demographic.\\nTo that end, the department introduced six possible categories in 2023 and earlier this year announced that they would remain in place into 2025. They are:\\n\\nHealthcare occupations\\nScience, technology, engineering, and mathematics (STEM) professions\\nTrades occupations, such as carpenters, plumbers, and contractors\\nTransport occupations\\nAgriculture and agri-food occupations\\nFrench-language proficiency\\n\\nDraws for this category are not program-specific and permanent resident applicants must be in the Express Entry application pool to be eligible.\\nGet a Free Express Entry Assessment\\n\\n\\n\\nShare this article\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nShare this article\\n\\n\\nCopy link\\r\\n\\t\\t\\t\\t\\t\\t\\t\\n\\nFacebook\\r\\n\\t\\t\\t\\t\\t\\t\\t\\n\\nE-mail\\r\\n\\t\\t\\t\\t\\t\\t\\t\\n\\nMessenger\\r\\n\\t\\t\\t\\t\\t\\t\\t\\n\\nReddit\\r\\n\\t\\t\\t\\t\\t\\t\\t\\n\\nTwitter\\r\\n\\t\\t\\t\\t\\t\\t\\t\\n\\nLinkedin\\r\\n\\t\\t\\t\\t\\t\\t\\t\\n\\nWhatsApp\\r\\n\\t\\t\\t\\t\\t\\t\\t\\n\\nTelegram\\r\\n\\t\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n119shares\\n\\n\\n \\n\\n\\nRelated topics\\n\\nCanada immigrateCanada permanent residencececCRSExpress EntryfstpfswpIRCCita \\n\\n\\n\\n\\nShare your voice\\n\\n\\n\\n\\nDid you find this article helpful?\\n\\n\\n\\nYes\\nNo\\n\\n\\n\\n\\n\\n\\n\\nThank you for your feedback.\\n\\n\\nShare this article\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nShare this article\\n\\n\\nCopy link\\r\\n\\t\\t\\t\\t\\t\\t\\t\\n\\nFacebook\\r\\n\\t\\t\\t\\t\\t\\t\\t\\n\\nE-mail\\r\\n\\t\\t\\t\\t\\t\\t\\t\\n\\nMessenger\\r\\n\\t\\t\\t\\t\\t\\t\\t\\n\\nReddit\\r\\n\\t\\t\\t\\t\\t\\t\\t\\n\\nTwitter\\r\\n\\t\\t\\t\\t\\t\\t\\t\\n\\nLinkedin\\r\\n\\t\\t\\t\\t\\t\\t\\t\\n\\nWhatsApp\\r\\n\\t\\t\\t\\t\\t\\t\\t\\n\\nTelegram\\r\\n\\t\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n119shares\\n\\n\\n\\nSubscribe to our newsletter\\n\\n\\n\\n\\n\\n\\nDid you find this article helpful?\\n\\n\\n\\n\\nPlease provide your feedback\\n\\n\\nSubmit\\nPlease provide a response\\n\\n\\n\\n\\n\\n\\n\\nThank you for your helpful feedback\\n\\n\\nPlease contact us if you would like to share additional feedback, have a question, or would like Canadian immigration assistance.\\n\\nDo you need Canadian immigration assistance? Contact the Contact Cohen Immigration Law firm by completing our form\\nSend us your feedback or your non-legal assistance questions by emailing us at media@canadavisa.com\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\nRelated articles\\n\\n\\nIRCC invites 6,300 Canadian Experience Class candidates in latest Express Entry draw\\n\\nExpress Entry\\n\\n\\n\\n\\n\\nStudy finds more newcomers are considering moving to escape housing costs\\n\\nCanada\\n\\n\\n\\n\\n\\nFrequently asked questions about visas for students, workers and tourists coming to Canada\\n\\nVisit\\n\\n\\n\\n\\n\\nOntario and British Columbia invite candidates to apply for provincial nomination\\n\\nProvinces\\n\\n\\n\\n\\n \\nTop Stories\\n\\n\\nMontreal ranks among top ten best cities for international students\\n\\nStudy\\n\\n\\n\\nIRCC invites 6,300 Canadian Experience Class candidates in latest Express Entry draw\\n\\nExpress Entry\\n\\n\\n\\nSix frequently asked questions about Canadian work permits\\n\\nWork\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJoin our free newsletter. Get Canada's top immigration stories delivered to your inbox.\\nSubscribe\\n\\n \\nMore in Work\\n\\n\\nSix frequently asked questions about Canadian work permits\\n\\nWork\\n\\n\\n\\n\\n\\nWhy IRCC may refuse your application for a post-graduation work permit\\n\\nWork\\n\\n\\n\\n\\n\\nAm I eligible for a Bridging Open Work Permit?\\n\\nWork\\n\\n\\n\\n\\n\\nFive free settlement resources for temporary foreign workers in Canada\\n\\nWork\\n\\n\\n\\n\\nRead more Work news\\n \\n\\n\\nTop Stories\\n\\n\\nMontreal ranks among top ten best cities for international students\\n\\nStudy\\n\\n\\n\\nIRCC invites 6,300 Canadian Experience Class candidates in latest Express Entry draw\\n\\nExpress Entry\\n\\n\\n\\nSix frequently asked questions about Canadian work permits\\n\\nWork\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSubscribe to our free newsletter\\nWe'll send you breaking news as soon as it happens. Sign up now!\\n\\n\\n\\nJoin 1+ million subscribers\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\nThe voice of Canadian immigration\\n\\n\\n\\n\\nTopics\\n\\nExpress Entry\\nCanada\\nProvinces\\nFamily Sponsorship\\nWork\\nCitizenship\\nStudy\\nVisit\\nLife in Canada\\n\\n\\n\\n\\n\\nWho we are\\n\\nAbout us\\nOur standards\\n\\n\\n\\nMedia partners\\n\\nMeet our partners\\nAdvertise with us\\n\\n\\n\\n\\n\\nContacts\\n\\n\\nContact us \\n+1 (888) 947-9445\\n1303 Greene Ave. Suite 200, Westmount, QC, H3Z 2A7\\nVisit the CanadaVisa Forum \\n\\n\\n\\n\\nFOLLOW US\\n\\n       \\n\\nVisit the CanadaVisa Forum \\n\\n\\n\\n© CIC News\\nPrivacy Policy\\n\\n\\n\\n\\nLink copied to clipboard\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nExpress Entry\\nCanada\\nProvinces\\nFamily Sponsorship\\nStudy\\nWork\\nVisit\\nCitizenship\\nLife in Canada\\nAbout us\\nMeet our partners\\n\\n\\n\\n\\n\\nSubscribe\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\")]\n"
     ]
    }
   ],
   "source": [
    "#pip install langchain_community\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "\n",
    "def crawl_data(url):\n",
    "    loader = WebBaseLoader(url)\n",
    "    docs = loader.load()\n",
    "    return docs\n",
    "\n",
    "print(crawl_data('https://www.cicnews.com/2024/07/express-entry-1390-candidates-invited-in-latest-pnp-only-draw-0745309.html#gs.bs9dnf'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044cd1c0-4114-40ce-84cb-cbf422c40994",
   "metadata": {},
   "source": [
    "#### Feed the crawl data into the LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "326805e4-76b7-45af-9a32-f5a639abab81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum CRS score for the last draw on May 31 was 522.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#pip install langchain_community\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "\n",
    "def crawl_data(url):\n",
    "    loader = WebBaseLoader(url)\n",
    "    docs = loader.load()\n",
    "    return docs\n",
    "\n",
    "docs = crawl_data('https://www.cicnews.com/2024/07/express-entry-1390-candidates-invited-in-latest-pnp-only-draw-0745309.html#gs.bs9dnf')\n",
    "\n",
    "load_dotenv()\n",
    "llm_model = ChatOpenAI(\n",
    "    model = 'gpt-3.5-turbo'\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template('''\n",
    "        Answer the questions: \n",
    "        Context: {context}\n",
    "        Question: {input}\n",
    "        ''')  \n",
    "\n",
    "# Create llm chain\n",
    "chain = create_stuff_documents_chain(\n",
    "    llm = llm_model, \n",
    "    prompt = prompt\n",
    ")\n",
    "\n",
    "response = chain.invoke({\n",
    "    'input': 'What is the  minimum CRS score for the last draw on May 31?',\n",
    "    'context': docs\n",
    "})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75b45fe-ff17-4554-a09c-ad4092e05025",
   "metadata": {},
   "source": [
    "### Split the the whole doc to chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "395ba033-268a-45c6-8fd1-f835694fa102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just take the notes that is import important chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f6723e60-b1f6-4826-8174-d4922c989ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_docs: 57\n",
      "The minimum CRS score for the last draw on May 31 was 522.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#pip install langchain_community\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def crawl_data(url):\n",
    "    loader = WebBaseLoader(url)\n",
    "    docs = loader.load()\n",
    "    \n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 200, \n",
    "        chunk_overlap = 20\n",
    "    )\n",
    "    split_docs = splitter.split_documents(docs)\n",
    "    print('split_docs:', len(split_docs))\n",
    "    return split_docs\n",
    "\n",
    "docs = crawl_data('https://www.cicnews.com/2024/07/express-entry-1390-candidates-invited-in-latest-pnp-only-draw-0745309.html#gs.bs9dnf')\n",
    "\n",
    "load_dotenv()\n",
    "llm_model = ChatOpenAI(\n",
    "    model = 'gpt-3.5-turbo'\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template('''\n",
    "        Answer the questions: \n",
    "        Context: {context}\n",
    "        Question: {input}\n",
    "        ''')  \n",
    "\n",
    "# Create llm chain\n",
    "chain = create_stuff_documents_chain(\n",
    "    llm = llm_model, \n",
    "    prompt = prompt\n",
    ")\n",
    "\n",
    "response = chain.invoke({\n",
    "    'input': 'What is the  minimum CRS score for the last draw on May 31?',\n",
    "    'context': docs\n",
    "})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b819c5e-f8e6-4235-a7c4-c1fb1a0237fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Converting chucnks to embedding, and store as vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1062b41d-78f8-4472-a4c8-fa2d454b39bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Retrival only releavent parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "276053e8-6d2b-4996-a5ca-5def58b9e13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum CRS score for the last draw on May 31 was 522.\n"
     ]
    }
   ],
   "source": [
    "# pip install faiss-cpu\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "\n",
    "def crawl_data(url):\n",
    "    loader = WebBaseLoader(url)\n",
    "    docs = loader.load()\n",
    "    \n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 200, \n",
    "        chunk_overlap = 20)\n",
    "    split_docs = splitter.split_documents(docs)\n",
    "    return split_docs\n",
    "\n",
    "def vectorization(docs):\n",
    "    embedding = OpenAIEmbeddings()\n",
    "\n",
    "    #FAISS (Facebook AI Similarity Search) index for efficient similarity search.\n",
    "    vectorStore = FAISS.from_documents(docs, embedding = embedding)\n",
    "    return vectorStore\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff98801-7422-4152-a1bd-452647e9d217",
   "metadata": {},
   "source": [
    "#### Create the chain as function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bff63ec9-e984-4463-91b5-bec95af05137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'What is the  minimum CRS score for the last draw on May 31?', 'context': [Document(metadata={'source': 'https://www.cicnews.com/2024/07/express-entry-1390-candidates-invited-in-latest-pnp-only-draw-0745309.html#gs.bs9dnf', 'title': 'IRCC invites 6,300 Canadian Experience Class candidates in latest Express Entry draw | CIC News', 'language': 'en-US'}, page_content=\"Today's minimum CRS score represent's the lowest score of the year in a non-category based selection draw and is also lower than the last CEC-only draw on May 31 (522).\"), Document(metadata={'source': 'https://www.cicnews.com/2024/07/express-entry-1390-candidates-invited-in-latest-pnp-only-draw-0745309.html#gs.bs9dnf', 'title': 'IRCC invites 6,300 Canadian Experience Class candidates in latest Express Entry draw | CIC News', 'language': 'en-US'}, page_content='The department issued 6,300 ITAs in a draw for Canadian Experience Class (CEC) candidates.\\nCandidates required a minimum Comprehensive Ranking System (CRS) score of 515 to be considered.'), Document(metadata={'source': 'https://www.cicnews.com/2024/07/express-entry-1390-candidates-invited-in-latest-pnp-only-draw-0745309.html#gs.bs9dnf', 'title': 'IRCC invites 6,300 Canadian Experience Class candidates in latest Express Entry draw | CIC News', 'language': 'en-US'}, page_content='an additional 600 CRS points on top of their existing score. For example, an Express Entry candidate with a score of 300 that is successfully nominated will then have an overall CRS of 900.'), Document(metadata={'source': 'https://www.cicnews.com/2024/07/express-entry-1390-candidates-invited-in-latest-pnp-only-draw-0745309.html#gs.bs9dnf', 'title': 'IRCC invites 6,300 Canadian Experience Class candidates in latest Express Entry draw | CIC News', 'language': 'en-US'}, page_content='DateDraw TypeNumber of ITAsMinimum CRS\\n\\n\\n\\n\\nJuly 17Canadian Experience Class6,300515\\n\\n\\nJuly 16Provincial Nominee Program1,391670\\n\\n\\nJuly 8French proficiency3,200420')], 'answer': 'The minimum CRS score for the last draw on May 31 was 522.'}\n"
     ]
    }
   ],
   "source": [
    "# pip install faiss-cpu\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "def crawl_data(url):\n",
    "    loader = WebBaseLoader(url)\n",
    "    docs = loader.load()\n",
    "    \n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 200, \n",
    "        chunk_overlap = 20)\n",
    "    split_docs = splitter.split_documents(docs)\n",
    "    return split_docs\n",
    "\n",
    "def vectorization(docs):\n",
    "    embedding = OpenAIEmbeddings()\n",
    "    vectorStore = FAISS.from_documents(docs, embedding = embedding)\n",
    "    return vectorStore\n",
    "\n",
    "def create_chain(vectorStore):\n",
    "    llm_model = ChatOpenAI(\n",
    "    model = 'gpt-3.5-turbo')\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template('''\n",
    "            Answer the questions: \n",
    "            Context: {context}\n",
    "            Question: {input}\n",
    "            ''')  \n",
    "    \n",
    "    # Create llm chain\n",
    "    chain = create_stuff_documents_chain(\n",
    "        llm = llm_model, \n",
    "        prompt = prompt\n",
    "    )\n",
    "    \n",
    "    #A retrieval-augmented generation (RAG) pipeline, which combines a language model with a vector store \n",
    "    #to answer questions based on the context retrieved from the vector store.\n",
    "    retriever = vectorStore.as_retriever() # give 5 best results  or you can use as_retriever(search_kwargs={\"k\": 1})\n",
    "    retriever_chain = create_retrieval_chain(retriever, chain)\n",
    "\n",
    "    return retriever_chain\n",
    "    \n",
    "\n",
    "\n",
    "docs = crawl_data('https://www.cicnews.com/2024/07/express-entry-1390-candidates-invited-in-latest-pnp-only-draw-0745309.html#gs.bs9dnf')\n",
    "vectorStore = vectorization(docs)\n",
    "chain = create_chain(vectorStore)\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "response = chain.invoke({\n",
    "    'input': 'What is the  minimum CRS score for the last draw on May 31?',\n",
    "    'context': docs\n",
    "})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e93bdedd-ad12-4727-bd48-803300fbd8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum CRS score for the last draw on May 31 was 522.\n"
     ]
    }
   ],
   "source": [
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa47dc0a-4a78-4d05-9461-cf3428c4e34f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3f6f2a-3a14-47b4-8e67-6cd87bf758c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
