{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMCHa3nhCx7+vc0dt+cAo6e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"bOzbnbzoZM70","executionInfo":{"status":"ok","timestamp":1733110060584,"user_tz":300,"elapsed":10482,"user":{"displayName":"Aarij Anwer","userId":"14626287556709569185"}}},"outputs":[],"source":["!pip install langchain-core langgraph>0.2.27"]},{"cell_type":"code","source":["from google.colab import userdata\n","\n","NVIDIA_API_KEY = userdata.get('NVIDIA_API_KEY')\n","LANGCHAIN_API_KEY = userdata.get('LANGCHAIN_API_KEY')\n","LANGCHAIN_TRACING_V2 = userdata.get('LANGCHAIN_TRACING_V2')\n","LANGCHAIN_PROJECT = userdata.get('LANGCHAIN_PROJECT')\n","\n","print(NVIDIA_API_KEY)\n","print(LANGCHAIN_API_KEY)\n","print(LANGCHAIN_TRACING_V2)\n","print(LANGCHAIN_PROJECT)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qIXOfMn5aLZ4","executionInfo":{"status":"ok","timestamp":1733110301847,"user_tz":300,"elapsed":1372,"user":{"displayName":"Aarij Anwer","userId":"14626287556709569185"}},"outputId":"00a76df3-92e9-45f3-8646-bb3882173f98"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["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\n","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\n","true\n","project2\n"]}]},{"cell_type":"code","source":["!pip install -qU langchain-nvidia-ai-endpoints"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jFeAq6TBbRtQ","executionInfo":{"status":"ok","timestamp":1733110351086,"user_tz":300,"elapsed":6207,"user":{"displayName":"Aarij Anwer","userId":"14626287556709569185"}},"outputId":"20f10bce-33bc-413f-ff90-34e4fc3264ea"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.1/41.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/4.5 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["from langchain_nvidia_ai_endpoints import ChatNVIDIA\n","\n","model = ChatNVIDIA(model=\"meta/llama3-70b-instruct\", api_key=NVIDIA_API_KEY)"],"metadata":{"id":"v9n2LVyKbLVg","executionInfo":{"status":"ok","timestamp":1733110438448,"user_tz":300,"elapsed":3,"user":{"displayName":"Aarij Anwer","userId":"14626287556709569185"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["from langchain_core.messages import HumanMessage\n","\n","model.invoke([HumanMessage(content=\"Hi! I'm Bob\")])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2hw7KZcDbulF","executionInfo":{"status":"ok","timestamp":1733110474944,"user_tz":300,"elapsed":781,"user":{"displayName":"Aarij Anwer","userId":"14626287556709569185"}},"outputId":"d3c4fab5-261c-40be-e865-5a9289054dbe"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content=\"Hi Bob! It's nice to meet you. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'role': 'assistant', 'content': \"Hi Bob! It's nice to meet you. Is there something I can help you with or would you like to chat?\", 'token_usage': {'prompt_tokens': 15, 'total_tokens': 41, 'completion_tokens': 26}, 'finish_reason': 'stop', 'model_name': 'meta/llama3-70b-instruct'}, id='run-bcac3beb-7f27-4b2a-a5f5-55998b3024e2-0', usage_metadata={'input_tokens': 15, 'output_tokens': 26, 'total_tokens': 41}, role='assistant')"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["from langchain_core.messages import AIMessage\n","\n","model.invoke(\n","    [\n","        HumanMessage(content=\"Hi! I'm Bob\"),\n","        AIMessage(content=\"Hello Bob! How can I assist you today?\"),\n","        HumanMessage(content=\"What's my name?\"),\n","    ]\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eZfFsMZhcApL","executionInfo":{"status":"ok","timestamp":1733111065883,"user_tz":300,"elapsed":539,"user":{"displayName":"Aarij Anwer","userId":"14626287556709569185"}},"outputId":"af362749-0f64-45ec-f626-341029f2a893"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='I remember! Your name is Bob!', additional_kwargs={}, response_metadata={'role': 'assistant', 'content': 'I remember! Your name is Bob!', 'token_usage': {'prompt_tokens': 40, 'total_tokens': 49, 'completion_tokens': 9}, 'finish_reason': 'stop', 'model_name': 'meta/llama3-70b-instruct'}, id='run-1745c801-5e5b-40a6-aa7a-68b8b4e4cae0-0', usage_metadata={'input_tokens': 40, 'output_tokens': 9, 'total_tokens': 49}, role='assistant')"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["from langgraph.checkpoint.memory import MemorySaver\n","from langgraph.graph import START, MessagesState, StateGraph\n","\n","from typing import Sequence\n","\n","from langchain_core.messages import BaseMessage\n","from langgraph.graph.message import add_messages\n","from typing_extensions import Annotated, TypedDict\n","\n","from langchain_core.messages import SystemMessage, trim_messages\n","\n","# Define a new graph\n","workflow = StateGraph(state_schema=MessagesState)\n","\n","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","\n","prompt_template = ChatPromptTemplate.from_messages(\n","    [\n","        (\n","            \"system\",\n","            \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\",\n","        ),\n","        MessagesPlaceholder(variable_name=\"messages\"),\n","    ]\n",")\n","\n","trimmer = trim_messages(\n","    max_tokens=65,\n","    strategy=\"last\",\n","    token_counter=model,\n","    include_system=True,\n","    allow_partial=False,\n","    start_on=\"human\",\n",")\n","\n","messages = [\n","    SystemMessage(content=\"you're a good assistant\"),\n","    HumanMessage(content=\"hi! I'm aarij\"),\n","    AIMessage(content=\"hi!\"),\n","    HumanMessage(content=\"I like vanilla ice cream\"),\n","    AIMessage(content=\"nice\"),\n","    HumanMessage(content=\"whats 2 + 2\"),\n","    AIMessage(content=\"4\"),\n","    HumanMessage(content=\"thanks\"),\n","    AIMessage(content=\"no problem!\"),\n","    HumanMessage(content=\"having fun?\"),\n","    AIMessage(content=\"yes!\"),\n","]\n","\n","trimmer.invoke(messages)\n","\n","class State(TypedDict):\n","    messages: Annotated[Sequence[BaseMessage], add_messages]\n","    language: str\n","\n","workflow = StateGraph(state_schema=State)\n","\n","def call_model(state: State):\n","    trimmed_messages = trimmer.invoke(state[\"messages\"])\n","    prompt = prompt_template.invoke(\n","        {\"messages\": trimmed_messages, \"language\": state[\"language\"]}\n","    )\n","    response = model.invoke(prompt)\n","    return {\"messages\": [response]}\n","\n","workflow.add_edge(START, \"model\")\n","workflow.add_node(\"model\", call_model)\n","\n","memory = MemorySaver()\n","app = workflow.compile(checkpointer=memory)\n"],"metadata":{"id":"NEtW7fXddsCB","executionInfo":{"status":"ok","timestamp":1733111681809,"user_tz":300,"elapsed":134,"user":{"displayName":"Aarij Anwer","userId":"14626287556709569185"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["config = {\"configurable\": {\"thread_id\": \"abc456\"}}\n","query = \"Hi! I'm Bob.\"\n","language = \"English\"\n","\n","input_messages = [HumanMessage(query)]\n","output = app.invoke(\n","    {\"messages\": input_messages, \"language\": language},\n","    config,\n",")\n","output[\"messages\"][-1].pretty_print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xcilJ2hwfQt1","executionInfo":{"status":"ok","timestamp":1733111795159,"user_tz":300,"elapsed":883,"user":{"displayName":"Aarij Anwer","userId":"14626287556709569185"}},"outputId":"98c0e21a-6b2d-440b-8642-5ff290751da6"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","Hi Bob! It's nice to meet you. I'm happy to assist you with any questions or topics you'd like to discuss. What's on your mind today?\n"]}]},{"cell_type":"code","source":["config = {\"configurable\": {\"thread_id\": \"abc678\"}}\n","query = \"What math problem did I ask?\"\n","language = \"English\"\n","\n","input_messages = messages + [HumanMessage(query)]\n","output = app.invoke(\n","    {\"messages\": input_messages, \"language\": language},\n","    config,\n",")\n","output[\"messages\"][-1].pretty_print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FjfBMhOqgdaK","executionInfo":{"status":"ok","timestamp":1733111807254,"user_tz":300,"elapsed":656,"user":{"displayName":"Aarij Anwer","userId":"14626287556709569185"}},"outputId":"ab4d866c-dc19-4db3-ebdc-f171f7de50af"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","You asked \"what's 2 + 2?\" and the answer is 4!\n"]}]},{"cell_type":"code","source":["config = {\"configurable\": {\"thread_id\": \"abc789\"}}\n","query = \"Hi I'm Todd, please tell me a joke.\"\n","language = \"English\"\n","\n","input_messages = [HumanMessage(query)]\n","for chunk, metadata in app.stream(\n","    {\"messages\": input_messages, \"language\": language},\n","    config,\n","    stream_mode=\"messages\",\n","):\n","    if isinstance(chunk, AIMessage):  # Filter to just model responses\n","        print(chunk.content, end=\"\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k5IpajEQg_0w","executionInfo":{"status":"ok","timestamp":1733111875156,"user_tz":300,"elapsed":911,"user":{"displayName":"Aarij Anwer","userId":"14626287556709569185"}},"outputId":"b0e37853-4ae2-4cbd-e0dc-68e6aed89fc0"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["Hi Todd! Here's a joke for you:\n","\n","Why couldn't the bicycle stand up by itself?\n","\n","(Wait for it...)\n","\n","Because it was two-tired!\n","\n","Hope that brought a smile to your face, Todd!"]}]}]}